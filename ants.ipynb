{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ants.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5fcGudEUw0-Y"
      },
      "source": [
        "## Ant Path Detection\n",
        "\n",
        "The purpose of this tool is to extract the path that a single ant takes in navigating its way across a surface. This program takes in a vido and generates a position file for use in MATLAB. \n",
        "\n",
        "For the path extraction to be successful, there are several important actions that must be taken. \n",
        "1. The video must first be cropped appropriately so that the ant's path does not intersect any object that moved in the video, including people. \n",
        "2. Next, once the extracted path image is generated, the user must erase any other dark content in the image. This may be somewhat difficult and require trial and error. The edited image will be uploaded, and then the points will be generated. \n",
        "3. If there are points away from the ant path, this means that photo must be edited again (to remove the area with the points) and reuploaded. \n",
        "\n",
        "The points are an approximation of the ant path. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KwK3zHbNvS3E"
      },
      "source": [
        "## Video Instructions\n",
        "\n",
        "Here are the instructions for uploading the video. Note that to upload a file you look at the four vertical icons on the left, click the bottom one several times, and then, from of the three horizontal icons that appear, click the leftmost one with the arrow.\n",
        "\n",
        "1. See where movement intersects the full ant path.\n",
        "2. Cut out up until there is no interfering movement.\n",
        "3. Cut out everything after the ant leaves the board.\n",
        "4. Create a zip file with the video and upload it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dXzY4KS8mdW0"
      },
      "source": [
        "## Execution Instructions\n",
        "\n",
        "Click each of the black circles with play buttons in them. There are some where you will have to wait for it to complete. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k5O58ejvwyZt"
      },
      "source": [
        "# install components not present in Colab by default\n",
        "!apt install imagemagick\n",
        "!apt install ffmpeg\n",
        "!pip3 install scikit-image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zuyQiPpNZr-F"
      },
      "source": [
        "# import Python packages \n",
        "import subprocess\n",
        "import os\n",
        "import glob\n",
        "import math \n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.cluster import mean_shift\n",
        "import cv2\n",
        "\n",
        "from google.colab import files"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jBkcqKNsmHwc"
      },
      "source": [
        "frame_rate = \"25\" #@param [\"15\", \"10\", \"20\", \"25\"]\n",
        "frame_rate = int(frame_rate)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZ8fCmXgj9mD"
      },
      "source": [
        "# the cropped + zipped video file you uploaded\n",
        "video_file = glob.glob('*.zip')\n",
        "\n",
        "# get the video's name and extension\n",
        "video_name = video_file[0].split('/')[-1].split('.')[0]\n",
        "ext = video_file[0].split('/')[-1].split('.')[1]\n",
        "\n",
        "# unzip the upload zip file\n",
        "subprocess.run(['unzip', video_file[0]])\n",
        "\n",
        "# produce 15 frame image data from the video\n",
        "subprocess.run(['ffmpeg', '-i', video_name+'.'+ext, '-r', frame_rate, '-q:v', '2', '-f', 'image2', f'./{video_name}_%d.jpeg'])\n",
        "\n",
        "# create img directory again\n",
        "if os.path.isdir(f'new_vi') != True:\n",
        "  subprocess.run(['mkdir','new_vi'])\n",
        "\n",
        "# renumber the images produced\n",
        "imgs = glob.glob(f'*.jpeg')\n",
        "largest_img = max([len(img.split('.')[0].split('_')[1]) for img in imgs])\n",
        "for img in imgs:\n",
        "  img_num = img.split('.')[0].split('_')[1]\n",
        "  zeros = largest_img - len(img_num)\n",
        "  new_num = ''.join(['0']*zeros)+img_num\n",
        "  new_img = img.split('.')[0].split('_')[0]+'_'+str(new_num)+'.jpeg'\n",
        "  subprocess.run(['mv', img, f'./new_vi/{new_img}'])\n",
        "\n",
        "# foresground setup\n",
        "c1 = ['convert', '-density','300']\n",
        "imgs = sorted(glob.glob('./new_vi/*.jpeg'))\n",
        "if len(imgs) % 2 != 0: # make file count even\n",
        "  imgs = imgs[:-1]\n",
        "\n",
        "# create img directory again\n",
        "if os.path.isdir('result_imgs') != True:\n",
        "  subprocess.run(['mkdir','r_imgs']) \n",
        "\n",
        "# step through 2 files at a time, generate the difference\n",
        "for index in range(0, len(imgs), 2):\n",
        "  c2 = ['-compose','difference','-composite','-colorspace','Gray']\n",
        "  name_1st = './r_imgs/'+'result'+imgs[index].split('/')[-1].split('.')[0].split('_')[1]+'.jpeg'\n",
        "  name_2nd = './r_imgs/'+'result'+imgs[index+1].split('/')[-1].split('.')[0].split('_')[1]+'.jpeg'\n",
        "  c2.append(name_1st)\n",
        "  c2.append(name_2nd)\n",
        "  try:\n",
        "    command = c1 + [imgs[index], imgs[index+1]] + c2\n",
        "  except IndexError:\n",
        "    pass \n",
        "  subprocess.run(command)\n",
        "\n",
        "imgs = list(filter(lambda elt: 'result' in elt, sorted(glob.glob('./r_imgs/*.jpeg'))))\n",
        "command_final = ['convert', '-compose','lighten', imgs[0]]\n",
        "remaining_imgs = []\n",
        "file_name = video_name+'.jpeg'\n",
        "for img in imgs[1:]:\n",
        "  remaining_imgs.append(img)\n",
        "  remaining_imgs.append('-composite')\n",
        "remaining_imgs.append(file_name)\n",
        "command = command_final + remaining_imgs\n",
        "subprocess.run(command)\n",
        "\n",
        "\n",
        "# remove lesser image differences\n",
        "T, threshInv = cv2.threshold(file_name, 55, 255, cv2.THRESH_BINARY)\n",
        "invIMG = file_name+'_inv.jpeg'\n",
        "cv2.imwrite(invImg, threshInv)\n",
        "\n",
        "# download file\n",
        "files.download(invImg)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SuuoS6qLsSRd"
      },
      "source": [
        "### Next Step\n",
        "\n",
        "So, the generated file has just been downloaded. Now is it time to remove the other white regions which are not part of the ant path using your photo edit tool of choice. Do this and reupload the file with the SAME name. \n",
        "\n",
        "For this next part, you will choose a number of points to approximate the ant path. Once you run the code chunk, observe the outputted image and see if there are any points flowing in space. If there are points, go back and edit the photo to remove these, and then reupload the photo, again with the same name. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TY5ojPIvvyl4"
      },
      "source": [
        "img = Image.open(invImg)\n",
        "\n",
        "arr = np.array(img.convert('L')).T[:,::-1]\n",
        "# get indices where there line is the pixel values is dark, ie <100\n",
        "indices = np.argwhere(arr < 100)\n",
        "\n",
        "for x in np.arange(40,1,-1):\n",
        "    print('{:.2f}: '.format(x), end='')\n",
        "    print(len(mean_shift(indices, bandwidth=x)[0]))\n",
        "\n",
        "points, labels = mean_shift(indices, bandwidth=3.0)\n",
        "\n",
        "plt.scatter(points[:,0], points[:,1])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "auavPKevrr_l",
        "outputId": "360858ec-2603-42f7-dba7-b3b46720f814"
      },
      "source": [
        "# img = cv2.imread('c0148.jpg')\n",
        "# # plt.imshow(img)\n",
        "\n",
        "# T, threshInv = cv2.threshold(img, 55, 255, cv2.THRESH_BINARY)\n",
        "# cv2.imwrite(f'thresh.jpeg', threshInv)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_KbRdg_2Q8U9"
      },
      "source": [
        "# from IPython.display import HTML, Image\n",
        "# from google.colab.output import eval_js\n",
        "# from base64 import b64decode\n",
        "\n",
        "# # uncomment if above is run\n",
        "# file_name = 'c0128.jpeg'\n",
        "\n",
        "# canvas_html = \"\"\"\n",
        "# <canvas width=%d height=%d></canvas>\n",
        "# <background\n",
        "# <button>Finish</button>\n",
        "# <script>\n",
        "# var canvas = document.querySelector('canvas')\n",
        "# var ctx = canvas.getContext('2d')\n",
        "# ctx.lineWidth = %d\n",
        "# var button = document.querySelector('button')\n",
        "# var mouse = {x: 0, y: 0}\n",
        "# canvas.addEventListener('mousemove', function(e) {\n",
        "#   mouse.x = e.pageX - this.offsetLeft\n",
        "#   mouse.y = e.pageY - this.offsetTop\n",
        "# })\n",
        "# canvas.onmousedown = ()=>{\n",
        "#   ctx.beginPath()\n",
        "#   ctx.moveTo(mouse.x, mouse.y)\n",
        "#   canvas.addEventListener('mousemove', onPaint)\n",
        "# }\n",
        "# canvas.onmouseup = ()=>{\n",
        "#   canvas.removeEventListener('mousemove', onPaint)\n",
        "# }\n",
        "# var onPaint = ()=>{\n",
        "#   ctx.lineTo(mouse.x, mouse.y)\n",
        "#   ctx.stroke()\n",
        "# }\n",
        "# var data = new Promise(resolve=>{\n",
        "#   button.onclick = ()=>{\n",
        "#     resolve(canvas.toDataURL('image/png'))\n",
        "#   }\n",
        "# })\n",
        "# </script>\n",
        "# \"\"\"\n",
        "\n",
        "# def draw(filename=file_name, w=400, h=200, line_width=1):\n",
        "#   display(HTML(canvas_html % (w, h, line_width)))\n",
        "#   data = eval_js(\"data\")\n",
        "#   binary = b64decode(data.split(',')[1])\n",
        "#   with open(filename, 'wb') as f:\n",
        "#     f.write(binary)\n",
        "#   return len(binary)\n",
        "\n",
        "# draw(file_name)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RaOLJ-V_MXYk"
      },
      "source": [
        "# \"\"\" \n",
        "# https://half-6.github.io/lf-freehand-cropper/\n",
        "# A promising example. Not exactly freehand, but choosing points is close enough. \n",
        "\n",
        "# https://netplayer.gr/crop/\n",
        "# Same thing, the code is more simple\n",
        "# \"\"\"\n",
        "\n",
        "# from IPython.display import HTML, Image\n",
        "# from google.colab.output import eval_js\n",
        "# from base64 import b64decode\n",
        "\n",
        "# # uncomment if above is run\n",
        "# file_name = 'c0128.jpeg'\n",
        "\n",
        "# canvas_html = \"\"\"\n",
        "# <canvas width=%d height=%d></canvas>\n",
        "# <background\n",
        "# <button>Finish</button>\n",
        "# <script>\n",
        "# var canvas = document.querySelector('canvas')\n",
        "# var ctx = canvas.getContext('2d')\n",
        "\n",
        "# imageObj = new Image()\n",
        "# imageObj.onload = function() {\n",
        "#     ctx.drawImage(imageObj, 0, 0)\n",
        "\n",
        "# };\n",
        "# imageObj.src = \"https://raw.githubusercontent.com/netplayer/crop/master/img.png\"\n",
        "\n",
        "# ctx.lineWidth = %d\n",
        "# var button = document.querySelector('button')\n",
        "# var mouse = {x: 0, y: 0}\n",
        "# canvas.addEventListener('mousemove', function(e) {\n",
        "#   mouse.x = e.pageX - this.offsetLeft\n",
        "#   mouse.y = e.pageY - this.offsetTop\n",
        "# })\n",
        "# canvas.onmousedown = ()=>{\n",
        "#   ctx.beginPath()\n",
        "#   ctx.moveTo(mouse.x, mouse.y)\n",
        "#   canvas.addEventListener('mousemove', onPaint)\n",
        "# }\n",
        "# canvas.onmouseup = ()=>{\n",
        "#   canvas.removeEventListener('mousemove', onPaint)\n",
        "# }\n",
        "# var onPaint = ()=>{\n",
        "#   ctx.lineTo(mouse.x, mouse.y)\n",
        "#   ctx.stroke()\n",
        "# }\n",
        "# var data = new Promise(resolve=>{\n",
        "#   button.onclick = ()=>{\n",
        "#     resolve(canvas.toDataURL('image/png'))\n",
        "#   }\n",
        "# })\n",
        "# </script>\n",
        "# \"\"\"\n",
        "\n",
        "# def draw(filename=file_name, w=400, h=200, line_width=1):\n",
        "#   display(HTML(canvas_html % (w, h, line_width)))\n",
        "#   data = eval_js(\"data\")\n",
        "#   binary = b64decode(data.split(',')[1])\n",
        "#   with open(filename, 'wb') as f:\n",
        "#     f.write(binary)\n",
        "#   return len(binary)\n",
        "\n",
        "# draw(file_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JqbHLrUOwaSY"
      },
      "source": [
        "# # Voronoi Stippling with Inversin\n",
        "# !git clone https://github.com/tmartin2/Rougier-2017.git\n",
        "\n",
        "# !pip3 uninstall scipy\n",
        "# !pip3 install scipy==1.1.0\n",
        "\n",
        "# from PIL import Image\n",
        "# import PIL.ImageOps    \n",
        "\n",
        "# image = Image.open('P70.jpeg')\n",
        "# inverted_image = PIL.ImageOps.invert(image)\n",
        "# inverted_image.save('P70_1.jpeg')\n",
        "\n",
        "# !python3 Rougier-2017/code/stippler.py --n_iter 20 --n_point 1000 --display 'P70_1.jpeg'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pxSJpkA-jQOM"
      },
      "source": [
        "# import cv2\n",
        "# import matplotlib.pyplot as plt\n",
        "# import numpy as np\n",
        "# from google.colab.patches import cv2_imshow\n",
        "\n",
        "# #image = cv2.imread('P70.jpeg')\n",
        "# #T, threshInv = cv2.threshold(image, 55, 255, cv2.THRESH_BINARY)\n",
        "# image = cv2.imread('P70_1.jpeg')\n",
        "# T, threshInv = cv2.threshold(image, 200, 255, cv2.THRESH_BINARY)\n",
        "# cv2_imshow(threshInv)\n",
        "\n",
        "\n",
        "# # pixel_vals = threshInv.reshape((-1,3)) \n",
        "# # pixel_vals = np.float32(pixel_vals)\n",
        "\n",
        "# # criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 100, 0.85) #criteria\n",
        "# # k = 3 # Choosing number of cluster\n",
        "# # retval, labels, centers = cv2.kmeans(pixel_vals, k, None, criteria, 10, cv2.KMEANS_RANDOM_CENTERS) \n",
        "\n",
        "# # centers = np.uint8(centers) # convert data into 8-bit values \n",
        "# # segmented_data = centers[labels.flatten()] # Mapping labels to center points( RGB Value)\n",
        "# # segmented_image = segmented_data.reshape((image.shape)) # reshape data into the original image dimensions\n",
        "# # plt.imshow(segmented_image)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TBaRJI1Inokf"
      },
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "from google.colab import files\n",
        "\n",
        "img = cv2.imread('c0148.jpg')\n",
        "T, threshInv = cv2.threshold(img, 55, 255, cv2.THRESH_BINARY)\n",
        "plt.imshow(img)\n",
        "\n",
        "\n",
        "# gray = cv2.cvtColor(threshInv, cv2.COLOR_BGR2GRAY)\n",
        "# ret, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
        "\n",
        "# n_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(thresh)\n",
        "\n",
        "# print(n_labels)\n",
        "\n",
        "# size_thresh = 1\n",
        "# for i in range(1, n_labels):\n",
        "#     if stats[i, cv2.CC_STAT_AREA] >= size_thresh:\n",
        "#         #print(stats[i, cv2.CC_STAT_AREA])\n",
        "#         x = stats[i, cv2.CC_STAT_LEFT]\n",
        "#         y = stats[i, cv2.CC_STAT_TOP]\n",
        "#         w = stats[i, cv2.CC_STAT_WIDTH]\n",
        "#         h = stats[i, cv2.CC_STAT_HEIGHT]\n",
        "#         cv2.rectangle(img, (x, y), (x+w, y+h), (0, 255, 0), thickness=1)\n",
        "# cv2.imwrite('P70a.jpeg', img)\n",
        "# plt.imshow(img)\n",
        "\n",
        "# specify region to remove "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JoB0lmxxp-HO"
      },
      "source": [
        "# import numpy as np\n",
        "# import cv2\n",
        "# from google.colab import files\n",
        "\n",
        "# img = cv2.imread('AL23.jpeg')\n",
        "# T, threshInv = cv2.threshold(img, 55, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "# gray = cv2.cvtColor(threshInv, cv2.COLOR_BGR2GRAY)\n",
        "# ret, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
        "\n",
        "# n_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(thresh)\n",
        "\n",
        "# print(n_labels)\n",
        "\n",
        "# size_thresh = 1\n",
        "# for i in range(1, n_labels):\n",
        "#     if stats[i, cv2.CC_STAT_AREA] >= size_thresh:\n",
        "#         #print(stats[i, cv2.CC_STAT_AREA])\n",
        "#         x = stats[i, cv2.CC_STAT_LEFT]\n",
        "#         y = stats[i, cv2.CC_STAT_TOP]\n",
        "#         w = stats[i, cv2.CC_STAT_WIDTH]\n",
        "#         h = stats[i, cv2.CC_STAT_HEIGHT]\n",
        "#         cv2.rectangle(img, (x, y), (x+w, y+h), (0, 255, 0), thickness=1)\n",
        "# cv2.imwrite('AL.jpeg', img)\n",
        "# plt.imshow(img)\n",
        "\n",
        "# # specify region to remove "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}